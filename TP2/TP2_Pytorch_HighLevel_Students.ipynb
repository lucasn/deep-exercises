{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcd7260-dc6e-4119-8a51-10538f2b8115",
   "metadata": {
    "id": "0dcd7260-dc6e-4119-8a51-10538f2b8115"
   },
   "source": [
    "# Utilisation de PyTorch à plus haut niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca5da7-2405-424f-ba05-fd2245f54470",
   "metadata": {
    "id": "25ca5da7-2405-424f-ba05-fd2245f54470"
   },
   "source": [
    "Dans ce TP, on se familiarise avec les fonctionnalités de la librairie PyTorch pour la construction et l'apprentissage d'une architecture de réseau de neurones.\n",
    "\n",
    "On utilise à nouveau les données MNIST et on considère la même architecture \"dense\" (pas de Convolution ici) que dans le TP1.  Les images sont donc considérées comme des vecteurs de tailles 28*28.\n",
    "\n",
    "Attention, on rappelle que les architectures PyTorch prennent les données en lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e09c76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Lambda\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a384bb41-5fdf-441a-8cc1-c6285fb48ab8",
   "metadata": {
    "id": "a384bb41-5fdf-441a-8cc1-c6285fb48ab8"
   },
   "source": [
    "## 1 - Chargement et lecture des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282b73d-6730-46e1-aa82-fb4b7046924a",
   "metadata": {
    "id": "d282b73d-6730-46e1-aa82-fb4b7046924a"
   },
   "source": [
    "PyTorch fournit deux classes `torch.utils.data.DataLoader` et `torch.utils.data.Dataset` pour utiliser des jeux de données pré-chargés ou des données externes.\n",
    "\n",
    " `Dataset` stocke les échantillons et les labels correspondants, tandis que  `DataLoader` fournit un itérateur pour un accès facile aux échantillons.\n",
    "\n",
    "En utilisant la classe `DataLoader`, on peut de manière générique appliquer des transformations à la volée pendant l'itération sur le jeu de données (arguments `transform` et `target_transform`), et faire en sorte que l'itération sur le tenseur fourni se fasse dans un ordre aléatoire (argument `shuffle`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13285f74-a4f7-4b46-aa95-72cb8d733407",
   "metadata": {
    "id": "13285f74-a4f7-4b46-aa95-72cb8d733407"
   },
   "source": [
    "**Vous pourrez vous aider de ce [tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#datasets-dataloaders) pour répondre aux questions de cette partie.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014a278-15d8-4fe6-8460-6c24627b934a",
   "metadata": {
    "id": "8014a278-15d8-4fe6-8460-6c24627b934a"
   },
   "source": [
    "> Créer une composition des deux transformations à appliquer sur les images:\n",
    "> - La transformée `ToTensor` fait automatiquement la normalisation des pixels.\n",
    "> - La transformée `Lambda` permet d'appliquer une fonction quelconque, ici pour changer la forme du tenseur (d'une image en un vecteur).\n",
    "> - La transformée `Compose` permet la composition de transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc3c8d3-41c4-4251-a31f-89803eebe1c1",
   "metadata": {
    "id": "ffc3c8d3-41c4-4251-a31f-89803eebe1c1"
   },
   "outputs": [],
   "source": [
    "transform_composition = Compose([ToTensor(), Lambda(lambda t : t.view(1, -1))])\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_composition\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_composition\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6db00-9f1b-4463-ae03-afbf4e8d6199",
   "metadata": {
    "id": "f4a6db00-9f1b-4463-ae03-afbf4e8d6199"
   },
   "source": [
    "> Créer des `DataLoader` pour les jeux de données d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11d78d76-565e-49b7-bf70-2e9085679e48",
   "metadata": {
    "id": "11d78d76-565e-49b7-bf70-2e9085679e48",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N0ZnIT1mF5_a",
   "metadata": {
    "id": "N0ZnIT1mF5_a"
   },
   "source": [
    "> Vérifier que vous pouvez extraire des échantillon batch de données d'apprentissage, en itérant sur le DataLoader construit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae751d56-6788-4319-9cdf-1a0cf80f5d05",
   "metadata": {
    "id": "ae751d56-6788-4319-9cdf-1a0cf80f5d05",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 784])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].view(28, 28)\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(f'Label: {label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34ed3a-60e1-4f21-8def-547b5d5c1cbc",
   "metadata": {
    "id": "bc34ed3a-60e1-4f21-8def-547b5d5c1cbc"
   },
   "source": [
    "## 2 - Différenciation automatique avec Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4caad-3a8f-4429-acc1-4712d3e52011",
   "metadata": {
    "id": "d4b4caad-3a8f-4429-acc1-4712d3e52011"
   },
   "source": [
    "Pour calculer des gradients et mettre en oeuvre une descente de gradient, PyTorch dispose du moteur de différenciation automatique `torch.autograd`, qui permet le calcul automatique du gradient pour n'importe quel graphe computationnel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1d15f-f4c2-4cff-a64a-aa767d243b62",
   "metadata": {
    "id": "05c1d15f-f4c2-4cff-a64a-aa767d243b62"
   },
   "source": [
    "**Consulter ce [tutorial](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) pour répondre aux questions de cette partie.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2190d05-5abd-4793-aa57-44d4dfd3d5a5",
   "metadata": {
    "id": "d2190d05-5abd-4793-aa57-44d4dfd3d5a5"
   },
   "source": [
    ">  On considère la fonction\n",
    "$$ (w,b) \\in \\mathbb{R}^5  \\times \\mathbb R \\mapsto   \\sum_{j=0}^4  j  \\cdot\\left(\\sin (w_j) +b \\right)^2  .$$\n",
    "> En utilisant autograd, calculer le gradient de cette fontion au point w=0, b = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b3c4410-c7d6-4cd6-85d2-eb562ce968d2",
   "metadata": {
    "id": "9b3c4410-c7d6-4cd6-85d2-eb562ce968d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 4., 6., 8.])\n",
      "tensor([20.])\n"
     ]
    }
   ],
   "source": [
    "w = torch.zeros(5, requires_grad=True)\n",
    "b = torch.ones(1, requires_grad=True)\n",
    "\n",
    "func = 0\n",
    "for j in range(5):\n",
    "    func += j * torch.pow(torch.sin(w[j]) + b, 2)\n",
    "\n",
    "func.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XKluI4LjXVFP",
   "metadata": {
    "id": "XKluI4LjXVFP"
   },
   "source": [
    "> Reprendre l'implémentation du réseau de neurone construit \"à la main dans le TP1\", en ne gardant que la méthodes `forward` qui ne renverra que l'activation de la dernière couche. On appellera `Net_sans_gradients` la classe ainsi créée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "Z9UHGQVpLv2z",
   "metadata": {
    "id": "Z9UHGQVpLv2z"
   },
   "outputs": [],
   "source": [
    "class Net_sans_gradients:\n",
    "    def __init__(self, layers_size = [784, 30, 20, 10]):\n",
    "        self.layers_size = layers_size\n",
    "        self.n_layers = len(layers_size) - 1\n",
    "        self.b = [None]\n",
    "        for layer_size in layers_size[1:]:\n",
    "            self.b.append(torch.zeros(1, layer_size, requires_grad=True))\n",
    "\n",
    "        self.w = [None]\n",
    "        for previous_layer, actual_layer in zip(layers_size, layers_size[1:]):\n",
    "            self.w.append(torch.normal(0, 1, size=(previous_layer, actual_layer), requires_grad=True))\n",
    "\n",
    "    def forward(self, a0):\n",
    "            a0 = a0.view(1, -1)\n",
    "\n",
    "            assert a0.size() == (1, self.layers_size[0]), f'Error: wrong input size ({a0.size()=})'\n",
    "\n",
    "            a = [a0]\n",
    "            z = [None]\n",
    "            for l in range(1, self.n_layers + 1):\n",
    "                z.append(torch.mm(a[l-1], self.w[l] + self.b[l]))\n",
    "                a.append(logistic(z[l]))\n",
    "\n",
    "                assert z[l].size() == (1, self.layers_size[l])\n",
    "                assert a[l].size() == (1, self.layers_size[l])\n",
    "\n",
    "            return a[self.n_layers]\n",
    "\n",
    "def logistic(x):\n",
    "    return 1/(1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6iOx7WfdPW02",
   "metadata": {
    "id": "6iOx7WfdPW02"
   },
   "source": [
    "> Vérifier ensuite que l'on peut obtenir à l'aide d'autograd le gradient de la perte [cross entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)  appliquée en sortie de ce réseau, par rapport aux paramètres du réseau,  sans avoir bien sûr à implémenter les expressions des gradients dans l'architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "mu6GfWKTLv7v",
   "metadata": {
    "id": "mu6GfWKTLv7v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5379e-07, -3.6419e-05, -1.3220e-05, -1.2052e-07,  1.1672e-07,\n",
       "         -1.3889e-05,  3.8230e-10,  5.8478e-06,  2.0804e-06,  2.5120e-05,\n",
       "          1.4126e-05,  9.1725e-09, -2.5452e-05, -1.5798e-06,  9.9393e-06,\n",
       "         -2.3217e-06,  9.6230e-08,  1.9437e-05, -2.6511e-07, -3.5338e-05],\n",
       "        [-8.0584e-06, -6.4673e-04, -2.3476e-04, -2.1402e-06,  2.0728e-06,\n",
       "         -2.4664e-04,  6.7890e-09,  1.0385e-04,  3.6945e-05,  4.4609e-04,\n",
       "          2.5086e-04,  1.6289e-07, -4.5197e-04, -2.8054e-05,  1.7650e-04,\n",
       "         -4.1229e-05,  1.7089e-06,  3.4517e-04, -4.7079e-06, -6.2754e-04],\n",
       "        [-7.6111e-04, -6.1082e-02, -2.2173e-02, -2.0214e-04,  1.9577e-04,\n",
       "         -2.3294e-02,  6.4121e-07,  9.8082e-03,  3.4894e-03,  4.2132e-02,\n",
       "          2.3693e-02,  1.5384e-05, -4.2688e-02, -2.6497e-03,  1.6670e-02,\n",
       "         -3.8940e-03,  1.6140e-04,  3.2601e-02, -4.4465e-04, -5.9270e-02],\n",
       "        [-3.4889e-09, -2.8000e-07, -1.0164e-07, -9.2661e-10,  8.9742e-10,\n",
       "         -1.0678e-07,  2.9393e-12,  4.4961e-08,  1.5995e-08,  1.9314e-07,\n",
       "          1.0861e-07,  7.0523e-11, -1.9568e-07, -1.2146e-08,  7.6418e-08,\n",
       "         -1.7850e-08,  7.3986e-10,  1.4944e-07, -2.0383e-09, -2.7170e-07],\n",
       "        [-7.6318e-04, -6.1249e-02, -2.2233e-02, -2.0269e-04,  1.9630e-04,\n",
       "         -2.3358e-02,  6.4295e-07,  9.8349e-03,  3.4988e-03,  4.2247e-02,\n",
       "          2.3758e-02,  1.5426e-05, -4.2804e-02, -2.6569e-03,  1.6716e-02,\n",
       "         -3.9046e-03,  1.6184e-04,  3.2690e-02, -4.4586e-04, -5.9431e-02],\n",
       "        [-2.2763e-10, -1.8268e-08, -6.6312e-09, -6.0455e-11,  5.8550e-11,\n",
       "         -6.9668e-09,  1.9177e-13,  2.9334e-09,  1.0436e-09,  1.2601e-08,\n",
       "          7.0860e-09,  4.6011e-12, -1.2767e-08, -7.9245e-10,  4.9857e-09,\n",
       "         -1.1646e-09,  4.8271e-11,  9.7501e-09, -1.3298e-10, -1.7726e-08],\n",
       "        [-2.6246e-05, -2.1064e-03, -7.6460e-04, -6.9705e-06,  6.7509e-06,\n",
       "         -8.0328e-04,  2.2112e-08,  3.3823e-04,  1.2033e-04,  1.4529e-03,\n",
       "          8.1704e-04,  5.3052e-07, -1.4721e-03, -9.1372e-05,  5.7486e-04,\n",
       "         -1.3428e-04,  5.5657e-06,  1.1242e-03, -1.5333e-05, -2.0439e-03],\n",
       "        [-2.8761e-05, -2.3082e-03, -8.3785e-04, -7.6384e-06,  7.3977e-06,\n",
       "         -8.8024e-04,  2.4230e-08,  3.7063e-04,  1.3185e-04,  1.5921e-03,\n",
       "          8.9531e-04,  5.8134e-07, -1.6131e-03, -1.0013e-04,  6.2994e-04,\n",
       "         -1.4714e-04,  6.0989e-06,  1.2319e-03, -1.6802e-05, -2.2397e-03],\n",
       "        [-8.5667e-06, -6.8752e-04, -2.4957e-04, -2.2752e-06,  2.2035e-06,\n",
       "         -2.6219e-04,  7.2172e-09,  1.1040e-04,  3.9275e-05,  4.7423e-04,\n",
       "          2.6668e-04,  1.7316e-07, -4.8048e-04, -2.9824e-05,  1.8764e-04,\n",
       "         -4.3829e-05,  1.8167e-06,  3.6694e-04, -5.0048e-06, -6.6712e-04],\n",
       "        [-7.4520e-04, -5.9806e-02, -2.1709e-02, -1.9791e-04,  1.9168e-04,\n",
       "         -2.2808e-02,  6.2781e-07,  9.6032e-03,  3.4164e-03,  4.1252e-02,\n",
       "          2.3198e-02,  1.5063e-05, -4.1796e-02, -2.5943e-03,  1.6322e-02,\n",
       "         -3.8126e-03,  1.5803e-04,  3.1920e-02, -4.3536e-04, -5.8032e-02],\n",
       "        [-7.1157e-04, -5.7107e-02, -2.0729e-02, -1.8898e-04,  1.8303e-04,\n",
       "         -2.1778e-02,  5.9948e-07,  9.1698e-03,  3.2622e-03,  3.9390e-02,\n",
       "          2.2151e-02,  1.4383e-05, -3.9910e-02, -2.4772e-03,  1.5585e-02,\n",
       "         -3.6405e-03,  1.5089e-04,  3.0479e-02, -4.1571e-04, -5.5412e-02],\n",
       "        [-7.5603e-04, -6.0675e-02, -2.2025e-02, -2.0079e-04,  1.9446e-04,\n",
       "         -2.3139e-02,  6.3693e-07,  9.7428e-03,  3.4661e-03,  4.1851e-02,\n",
       "          2.3535e-02,  1.5282e-05, -4.2403e-02, -2.6320e-03,  1.6559e-02,\n",
       "         -3.8680e-03,  1.6032e-04,  3.2384e-02, -4.4169e-04, -5.8875e-02],\n",
       "        [-3.8841e-12, -3.1171e-10, -1.1315e-10, -1.0315e-12,  9.9905e-13,\n",
       "         -1.1888e-10,  3.2722e-15,  5.0053e-11,  1.7807e-11,  2.1501e-10,\n",
       "          1.2091e-10,  7.8509e-14, -2.1785e-10, -1.3522e-11,  8.5072e-11,\n",
       "         -1.9872e-11,  8.2365e-13,  1.6637e-10, -2.2691e-12, -3.0247e-10],\n",
       "        [-7.5649e-04, -6.0712e-02, -2.2038e-02, -2.0091e-04,  1.9458e-04,\n",
       "         -2.3153e-02,  6.3732e-07,  9.7486e-03,  3.4682e-03,  4.1877e-02,\n",
       "          2.3549e-02,  1.5291e-05, -4.2429e-02, -2.6336e-03,  1.6569e-02,\n",
       "         -3.8703e-03,  1.6042e-04,  3.2403e-02, -4.4195e-04, -5.8910e-02],\n",
       "        [-7.6338e-04, -6.1265e-02, -2.2239e-02, -2.0274e-04,  1.9635e-04,\n",
       "         -2.3364e-02,  6.4313e-07,  9.8375e-03,  3.4998e-03,  4.2258e-02,\n",
       "          2.3764e-02,  1.5430e-05, -4.2816e-02, -2.6576e-03,  1.6720e-02,\n",
       "         -3.9056e-03,  1.6188e-04,  3.2698e-02, -4.4598e-04, -5.9447e-02],\n",
       "        [-7.6376e-04, -6.1295e-02, -2.2250e-02, -2.0284e-04,  1.9645e-04,\n",
       "         -2.3376e-02,  6.4345e-07,  9.8424e-03,  3.5015e-03,  4.2279e-02,\n",
       "          2.3776e-02,  1.5438e-05, -4.2837e-02, -2.6589e-03,  1.6729e-02,\n",
       "         -3.9075e-03,  1.6196e-04,  3.2715e-02, -4.4620e-04, -5.9477e-02],\n",
       "        [-9.4696e-05, -7.5998e-03, -2.7587e-03, -2.5150e-05,  2.4357e-05,\n",
       "         -2.8983e-03,  7.9779e-08,  1.2203e-03,  4.3414e-04,  5.2421e-03,\n",
       "          2.9479e-03,  1.9141e-06, -5.3112e-03, -3.2967e-04,  2.0741e-03,\n",
       "         -4.8448e-04,  2.0081e-05,  4.0562e-03, -5.5323e-05, -7.3743e-03],\n",
       "        [-1.3792e-07, -1.1069e-05, -4.0180e-06, -3.6631e-08,  3.5477e-08,\n",
       "         -4.2213e-06,  1.1620e-10,  1.7774e-06,  6.3233e-07,  7.6351e-06,\n",
       "          4.2936e-06,  2.7879e-09, -7.7358e-06, -4.8017e-07,  3.0210e-06,\n",
       "         -7.0565e-07,  2.9248e-08,  5.9078e-06, -8.0578e-08, -1.0741e-05],\n",
       "        [-7.0765e-04, -5.6792e-02, -2.0615e-02, -1.8794e-04,  1.8202e-04,\n",
       "         -2.1658e-02,  5.9618e-07,  9.1193e-03,  3.2443e-03,  3.9173e-02,\n",
       "          2.2029e-02,  1.4304e-05, -3.9690e-02, -2.4636e-03,  1.5500e-02,\n",
       "         -3.6205e-03,  1.5006e-04,  3.0311e-02, -4.1342e-04, -5.5107e-02],\n",
       "        [-6.4739e-04, -5.1956e-02, -1.8860e-02, -1.7194e-04,  1.6652e-04,\n",
       "         -1.9814e-02,  5.4541e-07,  8.3428e-03,  2.9680e-03,  3.5838e-02,\n",
       "          2.0153e-02,  1.3086e-05, -3.6310e-02, -2.2538e-03,  1.4180e-02,\n",
       "         -3.3122e-03,  1.3729e-04,  2.7730e-02, -3.7822e-04, -5.0415e-02],\n",
       "        [-7.6043e-07, -6.1028e-05, -2.2153e-05, -2.0196e-07,  1.9559e-07,\n",
       "         -2.3274e-05,  6.4064e-10,  9.7994e-06,  3.4862e-06,  4.2095e-05,\n",
       "          2.3672e-05,  1.5371e-08, -4.2650e-05, -2.6473e-06,  1.6656e-05,\n",
       "         -3.8905e-06,  1.6126e-07,  3.2572e-05, -4.4425e-07, -5.9217e-05],\n",
       "        [-2.5410e-10, -2.0393e-08, -7.4024e-09, -6.7485e-11,  6.5358e-11,\n",
       "         -7.7769e-09,  2.1407e-13,  3.2745e-09,  1.1649e-09,  1.4066e-08,\n",
       "          7.9101e-09,  5.1361e-12, -1.4252e-08, -8.8461e-10,  5.5655e-09,\n",
       "         -1.3000e-09,  5.3884e-11,  1.0884e-08, -1.4845e-10, -1.9788e-08],\n",
       "        [-1.5394e-07, -1.2354e-05, -4.4845e-06, -4.0883e-08,  3.9595e-08,\n",
       "         -4.7114e-06,  1.2969e-10,  1.9837e-06,  7.0573e-07,  8.5214e-06,\n",
       "          4.7920e-06,  3.1115e-09, -8.6338e-06, -5.3591e-07,  3.3716e-06,\n",
       "         -7.8757e-07,  3.2644e-08,  6.5936e-06, -8.9932e-08, -1.1988e-05],\n",
       "        [-7.3991e-05, -5.9381e-03, -2.1555e-03, -1.9651e-05,  1.9032e-05,\n",
       "         -2.2646e-03,  6.2335e-08,  9.5350e-04,  3.3922e-04,  4.0959e-03,\n",
       "          2.3033e-03,  1.4956e-06, -4.1499e-03, -2.5759e-04,  1.6206e-03,\n",
       "         -3.7855e-04,  1.5691e-05,  3.1693e-03, -4.3227e-05, -5.7620e-03],\n",
       "        [-6.9489e-04, -5.5768e-02, -2.0244e-02, -1.8455e-04,  1.7874e-04,\n",
       "         -2.1268e-02,  5.8543e-07,  8.9549e-03,  3.1858e-03,  3.8467e-02,\n",
       "          2.1632e-02,  1.4046e-05, -3.8974e-02, -2.4192e-03,  1.5220e-02,\n",
       "         -3.5552e-03,  1.4736e-04,  2.9765e-02, -4.0597e-04, -5.4114e-02],\n",
       "        [-7.6367e-04, -6.1288e-02, -2.2247e-02, -2.0282e-04,  1.9643e-04,\n",
       "         -2.3373e-02,  6.4337e-07,  9.8412e-03,  3.5011e-03,  4.2274e-02,\n",
       "          2.3773e-02,  1.5436e-05, -4.2832e-02, -2.6586e-03,  1.6727e-02,\n",
       "         -3.9071e-03,  1.6194e-04,  3.2711e-02, -4.4615e-04, -5.9470e-02],\n",
       "        [-5.4447e-08, -4.3696e-06, -1.5862e-06, -1.4460e-08,  1.4005e-08,\n",
       "         -1.6664e-06,  4.5870e-11,  7.0165e-07,  2.4962e-07,  3.0140e-06,\n",
       "          1.6949e-06,  1.1006e-09, -3.0538e-06, -1.8955e-07,  1.1926e-06,\n",
       "         -2.7856e-07,  1.1546e-08,  2.3322e-06, -3.1809e-08, -4.2400e-06],\n",
       "        [-7.6375e-04, -6.1294e-02, -2.2249e-02, -2.0284e-04,  1.9645e-04,\n",
       "         -2.3375e-02,  6.4343e-07,  9.8422e-03,  3.5015e-03,  4.2279e-02,\n",
       "          2.3775e-02,  1.5438e-05, -4.2836e-02, -2.6589e-03,  1.6728e-02,\n",
       "         -3.9075e-03,  1.6196e-04,  3.2714e-02, -4.4619e-04, -5.9476e-02],\n",
       "        [-6.0255e-04, -4.8357e-02, -1.7553e-02, -1.6003e-04,  1.5498e-04,\n",
       "         -1.8441e-02,  5.0763e-07,  7.7648e-03,  2.7624e-03,  3.3355e-02,\n",
       "          1.8757e-02,  1.2179e-05, -3.3795e-02, -2.0977e-03,  1.3197e-02,\n",
       "         -3.0827e-03,  1.2778e-04,  2.5809e-02, -3.5202e-04, -4.6922e-02],\n",
       "        [-3.4675e-05, -2.7828e-03, -1.0101e-03, -9.2092e-06,  8.9190e-06,\n",
       "         -1.0613e-03,  2.9213e-08,  4.4685e-04,  1.5897e-04,  1.9195e-03,\n",
       "          1.0794e-03,  7.0089e-07, -1.9448e-03, -1.2072e-04,  7.5948e-04,\n",
       "         -1.7740e-04,  7.3532e-06,  1.4853e-03, -2.0258e-05, -2.7003e-03]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net_sans_gradients()\n",
    "out = net.forward(train_features[0])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "l = loss(out.squeeze(), train_labels[0])\n",
    "\n",
    "l.backward()\n",
    "\n",
    "net.w[2].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfoau5_9YHq-",
   "metadata": {
    "id": "dfoau5_9YHq-"
   },
   "source": [
    "## 3 - Construction du réseau par la fonction Sequential\n",
    "\n",
    "\n",
    "La fonction [`torch.nn.Sequential`](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#nn-sequential) permet de construire facilement un réseau par couches successives.\n",
    "\n",
    "\n",
    "> Reconstruire le réseau du TP1 par un appel à `torch.nn.Sequential`. Vous appelerez `my_net2` le réseau ainsi créé.\n",
    "> On pourra afficher les paramètres du réseau avec la fonction `named_parameters`, afin de visualiser ce qui a été créé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cWA--NSycB-6",
   "metadata": {
    "id": "cWA--NSycB-6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "2.weight\n",
      "2.bias\n",
      "4.weight\n",
      "4.bias\n"
     ]
    }
   ],
   "source": [
    "my_net2 = torch.nn.Sequential(\n",
    "    nn.Linear(784, 30),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(30,20),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(20,10),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "for param in my_net2.named_parameters():\n",
    "    print(param[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S_D9aVo4kdVj",
   "metadata": {
    "id": "S_D9aVo4kdVj"
   },
   "source": [
    "On peut obtenir la réponse du réseau `my_net2` sur le tenseur a par `my_net2(a)`\n",
    "> Le réseau n'est pas encore entrainé. Vérifier que les valeurs de cross-entropy et la précision sont très mauvaises :\n",
    "- sur un batch de l'échantillon d'apprentissage,\n",
    "- sur l'échantillon d'apprentissage complet,\n",
    "- sur l'échantillon de test complet.   \n",
    ">\n",
    "> On pourra par exemple utiliser la fonction [`accuracy`](https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html#id3) de `torchmetrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "XMwodtIji6O0",
   "metadata": {
    "id": "XMwodtIji6O0"
   },
   "outputs": [],
   "source": [
    "def verify_how_bad_it_is(model, x, y):\n",
    "    n = x.size(0)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    preds = []\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "    for i in range(n):\n",
    "        pred = model(x[i])\n",
    "        losses.append(loss(pred.squeeze(), y[i]))\n",
    "        preds.append(torch.argmax(pred))\n",
    "    \n",
    "    preds = torch.tensor(preds)\n",
    "\n",
    "    return accuracy(preds, y), losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5039105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250) tensor(2.3014)\n"
     ]
    }
   ],
   "source": [
    "acc, losses = verify_how_bad_it_is(my_net2, train_features, train_labels)\n",
    "print(acc, torch.mean(torch.tensor(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2q12lcevmsJ",
   "metadata": {
    "id": "d2q12lcevmsJ"
   },
   "source": [
    "## 4 - Entraînement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dLWWUUpfNss",
   "metadata": {
    "id": "3dLWWUUpfNss"
   },
   "source": [
    "> Calculer la [cross entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) pour un échantillon batch entre les probabilités prédites par `my_net2` et les vrais labels du batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56lkNEb_hXMe",
   "metadata": {
    "id": "56lkNEb_hXMe"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kc9Uf2wIwFtS",
   "metadata": {
    "id": "Kc9Uf2wIwFtS"
   },
   "source": [
    "Pour entraîner le modèle, c'est à dire ajuster les poids et les biais, nous allons mettre en œuvre une descente de gradient stochastique avec comme fonction objective la perte de cross validation (appliquée en sortie du réseau).\n",
    "\n",
    "Il faut pour cela choisir un optimiseur ; lire ce [tutorial](https://pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "On choisit ici d'utiliser l'optimiseur de descente de gradient standard, disponible dans Pytorch par la fonction [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD).\n",
    "\n",
    "> Construire un batch avec le dataloader en prenant m =256.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5B0g37D23u99",
   "metadata": {
    "id": "5B0g37D23u99"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "COcuMiSi7Tgp",
   "metadata": {
    "id": "COcuMiSi7Tgp"
   },
   "source": [
    "> En adaptant la boucle proposée [ici](https://pytorch.org/docs/stable/optim.html#taking-an-optimization-step) dans le tutoriel, effectuer une succsession de pas de descente de gradient sur la perte calculée à chaque fois sur un élément du batch.  \n",
    "> Assurez-vous de bien comprendre le sens de chacune des commandes de la boucle :\n",
    "> - quel est le sens de l'instruction `loss.backward()`\n",
    "> - Pourquoi est-il nécessaire d'appeler l'instruction `optimizer.zero_grad()` à chaque passage de la boucle ?  \n",
    "> Répéter plusieurs fois la descente de gradient le long du batch. Vérifier que le taux d'erreur du réseau calculé sur le bacth diminue effectivement le long de la descente de gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wG7a21Hy2D5a",
   "metadata": {
    "id": "wG7a21Hy2D5a"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ncTD4Idf9HM8",
   "metadata": {
    "id": "ncTD4Idf9HM8"
   },
   "source": [
    "L'approche précédente enchaîne des pas de gradient tels que chaque pas de gradient n'est calculé que sur un seul élément du batch, ce qui n'est pas la même chose que d'effectuer un seul pas de gradient calculé (cumulé) sur tout le batch (batch-SGD).\n",
    "\n",
    "Nous allons maintenant entraîner le réseau sur des batchs sucessifs avec une descente de gradiant SGD par batch, ce qui est l'approche standard pour entraîner un réseau.\n",
    "\n",
    "> Redéfinir un DataLoader pour des batchs de taille m = 64.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VC5n34IZZ1uz",
   "metadata": {
    "id": "VC5n34IZZ1uz"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W7kDieSlZ23Q",
   "metadata": {
    "id": "W7kDieSlZ23Q"
   },
   "source": [
    "\n",
    "> Utiliser la fonction `train_loop` proposée à [cette page](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html) pour ajuster les poids de `my_net2`. Il n'est pas nécessaire de réinitialiser les poids de `my_net2`, vous pouvez tout simplement repartir de l'état actuel du réseau.\n",
    "> Assurez-vous de bien comprendre chaque ligne de la fonction `train_loop`.\n",
    "\n",
    "> Evaluer les performances du réseau sur l'échantillon test, en utilisant par exemple la fonction `test_loop` proposée sur cette même [page](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wy_YYPhc--5h",
   "metadata": {
    "id": "wy_YYPhc--5h"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OdIfWdeBMZyq",
   "metadata": {
    "id": "OdIfWdeBMZyq"
   },
   "source": [
    "## 5 - Modules  \n",
    "\n",
    "La bibliothèque dédiée à la conception d'architecture de Pytorch se base sur la classe `Module`.\n",
    "\n",
    "De façon générale, les fonctionnalités de cette bibliothèque permettent de définir soi-même des classes, qui héritent de la classe `Module` (attention les constructeurs devront réaliser l'appel `super().__init__()`).\n",
    "\n",
    "Cette approche permet un contrôle plus fin et une utilisation beaucoup plus riche des réseaux, qu'avec la classe `Sequential` utilisée plus haut.\n",
    "\n",
    "> En consultant cette [page](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html), implémenter une classe `Net_avec_Module` pour définir la même architecture qu'utilisée précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p4jTosrXCPj0",
   "metadata": {
    "id": "p4jTosrXCPj0"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GhVLy2roTnFG",
   "metadata": {
    "id": "GhVLy2roTnFG"
   },
   "source": [
    "> Instancier un réseau `net3` de classe `Net_avec_Module`/ Entrainer ce réseau sur les données MNIST et évaluer l'erreur de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_e0Zp49em01f",
   "metadata": {
    "id": "_e0Zp49em01f"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "htnIg_hicysA",
   "metadata": {
    "id": "htnIg_hicysA"
   },
   "source": [
    "## 6 - Extraction et modification des matrices de poids\n",
    "\n",
    "Un réseau vient avec la collection de ses matrices de poids et de ses biais, dont les valeurs évoluent pendant la descente de gradient.\n",
    "\n",
    "Il existe plusieurs façons d'afficher les poids d'un réseau:\n",
    "- avec le dictionnaire `state_dict()`\n",
    "- avec les listes de `named_parameters()`\n",
    "- en appelant directement la couche par son nom, comme indiqué dans la classe défini avec module.\n",
    "\n",
    "> Instancier un nouveau réseau `net4` de la classe `Net_avec_Module`. Ne l'entrainez pas pour le moment, car nous voulons ainsi vérifier avec ce qui suit que les poids et les biais ne sont pas initialisés à 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HLH6s8oqjeXH",
   "metadata": {
    "id": "HLH6s8oqjeXH"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vS73-IJfMnqB",
   "metadata": {
    "id": "vS73-IJfMnqB"
   },
   "source": [
    "### Avec `state_dict()`\n",
    "\n",
    "La méthode `state_dict()` retourne un dictionnaire contenant une correspondance entre les noms des couches et leurs paramètres associés.\n",
    "\n",
    "> Itérer sur les clés du dictionnaire pour afficher ces dernières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9WZplNIbXnjZ",
   "metadata": {
    "id": "9WZplNIbXnjZ"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2inDJVjYQid",
   "metadata": {
    "id": "a2inDJVjYQid"
   },
   "source": [
    "Pour accéder aux poids d'une couche spécifique, on utilise  le dictionnaire `state_dict` avec le nom de la couche.\n",
    "> Afficher les poids et les biais de la deuxième couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coQLMJvhb480",
   "metadata": {
    "id": "coQLMJvhb480"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UJC3nFTFbrYL",
   "metadata": {
    "id": "UJC3nFTFbrYL"
   },
   "source": [
    "### Avec `named_parameters()`\n",
    "\n",
    "On peut aussi afficher les valeurs des paramètres à l'aide de la méthode `named_parameters()`, qui itère le long du modèle en fournissant  les noms des couches et les paramètres,  sous forme de tuples (nom, paramètre).\n",
    "> Afficher l'ensemble des paramètres du modèle en itérer le long du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZmX2V1OFM55k",
   "metadata": {
    "id": "ZmX2V1OFM55k"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "szqzWGlJgFSQ",
   "metadata": {
    "id": "szqzWGlJgFSQ"
   },
   "source": [
    "### Directement par nom de couche\n",
    "\n",
    "On peut aussi directement accéder aux biais et poids en utilisant le nom de la couche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HSMHa92YgF6f",
   "metadata": {
    "id": "HSMHa92YgF6f"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sb4kMNDFfaZ3",
   "metadata": {
    "id": "Sb4kMNDFfaZ3"
   },
   "source": [
    "> Modifier le biais de la deuxième couche en lui imposant la valeur $V = [1,2,3,1,2,3,1,2,3,1,1,1,2,3,1,2,3,1,2,3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xWRVaDNJfbKS",
   "metadata": {
    "id": "xWRVaDNJfbKS"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dKFrXpuCfwlS",
   "metadata": {
    "id": "dKFrXpuCfwlS"
   },
   "source": [
    "> Manipuler ainsi les poids du réseau à la main peut parfois empecher le cacul des gradients sur les itérations suivantes de la descente de gradient.\n",
    "> Vérifier que les dérivées partielles par rapport au biais seront bien \"maintenues\" par autograd, et assurez-vous enfin qu'il est toujours possible d'entrainer le modèle (attention à préciser les nouveaux poids à optimiser dans `optimizer`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4OsVrhmWebvv",
   "metadata": {
    "id": "4OsVrhmWebvv"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IIw-EVfZl6n2",
   "metadata": {
    "id": "IIw-EVfZl6n2"
   },
   "source": [
    "> Vérifier que les biais sont bien impactés par la descente de gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raL7c-tAqT87",
   "metadata": {
    "id": "raL7c-tAqT87"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7CHYE94NecMD",
   "metadata": {
    "id": "7CHYE94NecMD"
   },
   "source": [
    "> Comment faire pour \"geler\" une couche de poids ou de biais, c'est à dire ne pas faire de pas de gradient dans les directions qui correspondent à ces quantités à geler ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o_IIvvRefUoa",
   "metadata": {
    "id": "o_IIvvRefUoa"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moyfeO_ufXvM",
   "metadata": {
    "id": "moyfeO_ufXvM"
   },
   "source": [
    "## 6 - Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iCTuI4Qse-ch",
   "metadata": {
    "id": "iCTuI4Qse-ch"
   },
   "source": [
    "Il existe de nombreuses stratégies pour initialiser les couches d'un réseau (avant d'effectuer l'apprentissage par descente de gradient).\n",
    "\n",
    "On s'intéresse à plusieurs stratégies: poids à zero, poids constants, loi uniforme, loi normale, méthode de Xavier...\n",
    "\n",
    "\n",
    "> En utilisant les fonctionnalités du module [torch.nn.init](https://pytorch.org/docs/stable/nn.init.html), comparer ces initialisations en comparant les pertes et les taux de bon classement après un certain nombre d'épochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vql-tTBwfUev",
   "metadata": {
    "id": "Vql-tTBwfUev"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WAXX6J6fr1Z-",
   "metadata": {
    "id": "WAXX6J6fr1Z-"
   },
   "source": [
    "\n",
    "> Bonus : vérifier les distributions des poids initialisés correspond bien à ce qui est annoncé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y2xB0lFrCPfa",
   "metadata": {
    "id": "y2xB0lFrCPfa"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
